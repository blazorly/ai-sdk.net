using System.Runtime.CompilerServices;
using AiSdk.Abstractions;

namespace StreamingExample;

/// <summary>
/// A mock language model that simulates streaming responses.
/// This allows the example to run without requiring an API key.
/// </summary>
public class MockLanguageModel : ILanguageModel
{
    public string SpecificationVersion => "v3";
    public string Provider => "mock";
    public string ModelId => "mock-streaming-model";

    public Task<IReadOnlyDictionary<string, IReadOnlyList<string>>> GetSupportedUrlsAsync(
        CancellationToken cancellationToken = default)
    {
        var empty = new Dictionary<string, IReadOnlyList<string>>();
        return Task.FromResult<IReadOnlyDictionary<string, IReadOnlyList<string>>>(empty);
    }

    public Task<LanguageModelGenerateResult> GenerateAsync(
        LanguageModelCallOptions options,
        CancellationToken cancellationToken = default)
    {
        // For non-streaming, return a complete response
        var result = new LanguageModelGenerateResult
        {
            Text = "This is a complete response from the mock model. " +
                   "In a real scenario, this would be generated by an AI provider like OpenAI or Anthropic.",
            FinishReason = FinishReason.Stop,
            Usage = new Usage(
                InputTokens: 10,
                OutputTokens: 20,
                TotalTokens: 30
            )
        };

        return Task.FromResult(result);
    }

    public async IAsyncEnumerable<LanguageModelStreamChunk> StreamAsync(
        LanguageModelCallOptions options,
        [EnumeratorCancellation] CancellationToken cancellationToken = default)
    {
        // Simulate streaming by breaking the response into chunks
        var responseText = "This is a streaming response from the mock model. " +
                          "Each word is delivered as a separate chunk, " +
                          "simulating real-time token generation. " +
                          "In production, you would use a real AI provider.";

        var words = responseText.Split(' ');

        foreach (var word in words)
        {
            // Simulate network delay
            await Task.Delay(50, cancellationToken);

            yield return new LanguageModelStreamChunk
            {
                Type = ChunkType.TextDelta,
                Delta = word + " "
            };
        }

        // Final chunk with usage information
        yield return new LanguageModelStreamChunk
        {
            Type = ChunkType.Finish,
            FinishReason = FinishReason.Stop,
            Usage = new Usage(
                InputTokens: 10,
                OutputTokens: words.Length,
                TotalTokens: 10 + words.Length
            )
        };
    }
}
